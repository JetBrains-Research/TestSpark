name=My Plugin
!Indicator names
testGenerationMessage=Generating tests
buildMessage=Building project
searchMessage=Generating tests
generatingTestNumber=Generating test #
compilationTestsChecking=Compilation tests checking
testCasesSaving=Test cases saving
!Build error titles
buildErrorTitle=Build error
evosuiteErrorTitle=EvoSuite error
llmErrorTitle=LLM error
llmWarningTitle=LLM warning
!Quick Access and Generate Tests
removeAllMessage=Are you sure you want to remove all tests?\nThis action cannot be undone
confirmationTitle=Are You Sure?
!RunnerService
alreadyRunningNotificationTitle=Generation is already running
alreadyRunningTextNotificationText=You can generate more tests after the current test generation is complete.
!EvoSuite error messages
evosuiteErrorMessage=An exception occurred while executing EvoSuite: %s.\nPlease verify that you have set a valid path to a Java 11 binary in TestSpark Settings.
evosuiteErrorCommon=EvoSuite process error:
exceededTimeoutMessage=Exceeded timeout
nonZeroCodeMessage=Exited with non-zero exit code
unknownClassMessage=Unknown class, be sure its compilation path is correct
unknownClassError=Unknown class
errorWhileInitializingTargetClass=Error while initializing target class
incorrectJavaVersion=Incorrect java path
!LLM error messages
missingToken=The token for the LLM is not provided. You can set it in the Large Language Model Settings.
wrongToken=The provided token for LLM is not correct. Please update it in the Large Language Model Settings.
emptyResponse=LLM could not generate any tests for this class. Asking the AI assistance to fix its mistake.
emptyBuildPath=Build path is Empty!\nPlease make sure that IDEA recognizes all of your module or enter proper build path in settings
invalidLLMResult=The result is invalid or uses unknown commands due to randomness and lack of guarantees from Chat GPT.\nPlease try again
compilationError=The test generated by LLM is not compilable. Asking the AI assistance to fix its mistake.
serverProblems=LLM server is not responding
tooLongPrompt=The generated prompt is too long! Please, generate tests for single methods.
requestError=An error occurred during interaction with the LLM Platform. Code:
savingTestFileIssue=Plugin cannot save the test file
promptReduction=The generated prompt is too long, plugin reduced Large Language Model parameters.
!Build error messages
commonBuildErrorMessage=Please make sure that IntelliJ can build your project without any issues or provide the correct build command in the settings
sendingFeedback=Sending your request to LLM
testRunning=Test running
!Run caution message
runCautionMessage=By clicking "OK" you agree to run this code on your machine